{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport time\nimport gc\nimport glob\nimport json\nimport pprint\nimport joblib\nimport warnings\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nimport xgboost as xgb\nimport tensorflow as tf\n\nfrom collections import Counter\nfrom functools import partial\nfrom math import sqrt\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF\n\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\nfrom contextlib import contextmanager\nfrom pandas.io.json import json_normalize\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D, CuDNNLSTM, CuDNNGRU\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling2D, GlobalAveragePooling1D, GlobalAvgPool2D, \\\n    GlobalMaxPool2D\nfrom keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\nfrom keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, SpatialDropout2D\nfrom keras.applications.densenet import preprocess_input, DenseNet121\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\n\npreload = False\n\n\nclass PetFinderParser(object):\n\n    def __init__(self, debug=False):\n\n        self.debug = debug\n        self.sentence_sep = ' '\n\n        # Does not have to be extracted because main DF already contains description\n        self.extract_sentiment_text = False\n\n    def open_metadata_file(self, filename):\n        \"\"\"\n        Load metadata file.\n        \"\"\"\n        with open(filename, 'r') as f:\n            metadata_file = json.load(f)\n        return metadata_file\n\n    def open_sentiment_file(self, filename):\n        \"\"\"\n        Load sentiment file.\n        \"\"\"\n        with open(filename, 'r') as f:\n            sentiment_file = json.load(f)\n        return sentiment_file\n\n    def open_image_file(self, filename):\n        \"\"\"\n        Load image file.\n        \"\"\"\n        image = np.asarray(Image.open(filename))\n        return image\n\n    def parse_sentiment_file(self, file):\n        \"\"\"\n        Parse sentiment file. Output DF with sentiment features.\n        \"\"\"\n\n        file_sentiment = file['documentSentiment']\n        file_entities = [x['name'] for x in file['entities']]\n        file_entities = self.sentence_sep.join(file_entities)\n\n        # file_entities_new =[x['type'] for x in file['entities']]\n        # file_entities_new = self.sentence_sep.join(file_entities_new)\n\n        if self.extract_sentiment_text:\n            file_sentences_text = [x['text']['content'] for x in file['sentences']]\n            file_sentences_text = self.sentence_sep.join(file_sentences_text)\n        file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n\n        file_sentences_sentiment = pd.DataFrame.from_dict(\n            file_sentences_sentiment, orient='columns').sum()\n        file_sentences_sentiment = file_sentences_sentiment.add_prefix('document_').to_dict()\n\n        file_sentiment.update(file_sentences_sentiment)\n\n        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n        if self.extract_sentiment_text:\n            df_sentiment['text'] = file_sentences_text\n\n        df_sentiment['entities'] = file_entities\n        # df_sentiment['entities_type'] = file_entities_new\n        df_sentiment = df_sentiment.add_prefix('sentiment_')\n\n        return df_sentiment\n\n    def parse_metadata_file(self, file):\n        \"\"\"\n        Parse metadata file. Output DF with metadata features.\n        \"\"\"\n\n        file_keys = list(file.keys())\n\n        if 'labelAnnotations' in file_keys:\n            file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']))]\n            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n            file_top_desc = [x['description'] for x in file_annots]\n        else:\n            file_top_score = np.nan\n            file_top_desc = ['']\n\n        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n        file_crops = file['cropHintsAnnotation']['cropHints']\n\n        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n\n        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n\n        if 'importanceFraction' in file_crops[0].keys():\n            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n        else:\n            file_crop_importance = np.nan\n\n        df_metadata = {\n            'annots_score': file_top_score,\n            'color_score': file_color_score,\n            'color_pixelfrac': file_color_pixelfrac,\n            'crop_conf': file_crop_conf,\n            'crop_importance': file_crop_importance,\n            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n        }\n\n        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n        df_metadata = df_metadata.add_prefix('metadata_')\n\n        return df_metadata\n\n\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert (len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    rater_a = y\n    rater_b = y_pred\n    min_rating = None\n    max_rating = None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert (len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']\n\n\ndef rmse(actual, predicted):\n    return sqrt(mean_squared_error(actual, predicted))\n\n\n# Helper function for parallel data processing:\ndef extract_additional_features(pet_id, mode='train'):\n    pet_parser = PetFinderParser()\n    sentiment_filename = '../input/petfinder-adoption-prediction/{}_sentiment/{}.json'.format(mode, pet_id)\n    try:\n        sentiment_file = pet_parser.open_sentiment_file(sentiment_filename)\n        df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n        df_sentiment['PetID'] = pet_id\n    except FileNotFoundError:\n        df_sentiment = []\n\n    dfs_metadata = []\n    metadata_filenames = sorted(\n        glob.glob('../input/petfinder-adoption-prediction/{}_metadata/{}*.json'.format(mode, pet_id)))\n    if len(metadata_filenames) > 0:\n        for f in metadata_filenames:\n            metadata_file = pet_parser.open_metadata_file(f)\n            df_metadata = pet_parser.parse_metadata_file(metadata_file)\n            df_metadata['PetID'] = pet_id\n            dfs_metadata.append(df_metadata)\n        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n    dfs = [df_sentiment, dfs_metadata]\n\n    return dfs\n\n\ndef set_seed(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.set_random_seed(seed)\n\n\n# Helper Functions\n# ---------------------\n@contextmanager\ndef faith(title):\n    start_time = time.time()\n    yield\n    print(\">> {} - done in {:.0f}s\".format(title, time.time() - start_time))\n\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['uint8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem,\n                                                                              100 * (start_mem - end_mem) / start_mem))\n    return df\n\n\ndef clean_name(x):\n    x = str(x)\n    no_names = [\"No Name Yet\", \"Nameless\", \"no_Name_Yet\", \"No Name Yet God Bless\", \"-no Name-\", \"[No Name]\",\n                \"(No Name)\", \"No Names\", \"Not Yet Named\"]\n    for n in no_names:\n        x.replace(n, \"No Name\")\n    return x\n\n\ndef relative_age(cols):\n    pet_type = cols[0]\n    age = cols[1]\n    if pet_type == 1:\n        relage = age / 144  # Dog Avergae Life Span - 12 years\n    else:\n        relage = age / 180  # Cat Average Span - 15 years\n    return relage\n\n\ndef VerifibalePhotoAmy(number):\n    if number > 1:\n        vfp = 1\n    else:\n        vfp = 0\n    return vfp\n\n\ndef seo_value(cols):\n    photos = cols[0]\n    videos = cols[1]\n    seo = .7 * videos + .3 * photos\n    return seo\n\n\ndef genuine_name(cols):\n    name = cols[0]\n    quantity = cols[1]\n    try:\n        is_gen = int(len(name.split()) == 1)\n    except:\n        is_gen = np.nan\n    if int(quantity) > 1:\n        is_gen = 1\n    return is_gen\n\n\ndef rankbyG(alldata, group):\n    rank_telemetry = pd.DataFrame()\n    for unit in (alldata[group].unique()):\n        tf = alldata[alldata[group] == unit][['PetID', 'InstaFeature', group]]\n        col_name = \"Insta\" + str(group).title() + \"Rank\"\n        tf[col_name] = tf['InstaFeature'].rank(method='max')\n        rank_telemetry = pd.concat([rank_telemetry, tf[['PetID', col_name]]])\n        del tf\n    alldata = pd.merge(alldata, rank_telemetry, on=['PetID'], how='left')\n    return alldata\n\n\ndef get_new_columns(name, aggs):\n    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n\n\ndef agg_features(df, groupby, agg, prefix):\n    agg_df = df.groupby(groupby).agg(agg)\n    agg_df.columns = get_new_columns(prefix, agg)\n    return agg_df\n\n\ndef bounding_features(df, meta_path=\"../input/petfinder-adoption-prediction/train_metadata/\"):\n    \n    df_id = df['PetID']\n    vertex_xs = []\n    vertex_ys = []\n    bounding_confidences = []\n    bounding_importance_fracs = []\n    dominant_blues = []\n    dominant_greens = []\n    dominant_reds = []\n    dominant_pixel_fracs = []\n    dominant_scores = []\n    label_descriptions = []\n    label_scores = []\n    nf_count = 0\n    nl_count = 0\n    for pet in (df_id):\n        try:\n            with open(str(meta_path) + pet + '-1.json', 'r') as f:\n                data = json.load(f)\n            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n            vertex_xs.append(vertex_x)\n            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n            vertex_ys.append(vertex_y)\n            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n            bounding_confidences.append(bounding_confidence)\n            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n            bounding_importance_fracs.append(bounding_importance_frac)\n            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n            dominant_blues.append(dominant_blue)\n            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n            dominant_greens.append(dominant_green)\n            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n            dominant_reds.append(dominant_red)\n            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n            dominant_pixel_fracs.append(dominant_pixel_frac)\n            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n            dominant_scores.append(dominant_score)\n            if data.get('labelAnnotations'):\n                label_description = data['labelAnnotations'][0]['description']\n                label_descriptions.append(label_description)\n                label_score = data['labelAnnotations'][0]['score']\n                label_scores.append(label_score)\n            else:\n                nl_count += 1\n                label_descriptions.append('nothing')\n                label_scores.append(-1)\n        except FileNotFoundError:\n            nf_count += 1\n            vertex_xs.append(-1)\n            vertex_ys.append(-1)\n            bounding_confidences.append(-1)\n            bounding_importance_fracs.append(-1)\n            dominant_blues.append(-1)\n            dominant_greens.append(-1)\n            dominant_reds.append(-1)\n            dominant_pixel_fracs.append(-1)\n            dominant_scores.append(-1)\n            label_descriptions.append('nothing')\n            label_scores.append(-1)\n    df.loc[:, 'vertex_x'] = vertex_xs\n    df.loc[:, 'vertex_y'] = vertex_ys\n    df.loc[:, 'bounding_confidence'] = bounding_confidences\n    df.loc[:, 'bounding_importance'] = bounding_importance_fracs\n    df.loc[:, 'dominant_blue'] = dominant_blues\n    df.loc[:, 'dominant_green'] = dominant_greens\n    df.loc[:, 'dominant_red'] = dominant_reds\n    df.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n    df.loc[:, 'dominant_score'] = dominant_scores\n    # df.loc[:, 'label_description'] = label_descriptions\n    df.loc[:, 'label_score'] = label_scores\n    return df\n\n\ndef open_breeds_info_file(filename):\n    with open(filename, 'r') as f:\n        breedsdata_file = json.load(f)\n    return breedsdata_file\n\n\ndef parse_sentiment_file(file):\n    df = pd.DataFrame()\n    breeds_file = open_breeds_info_file(file)\n    cat_data, dog_data = breeds_file['cat_breeds'], breeds_file['dog_breeds']\n    ### Cats\n    for idx, cat_breed in enumerate((cat_data.keys())):\n        temp = pd.DataFrame.from_dict(json_normalize(cat_data[cat_breed]), orient='columns')\n        temp.insert(0, 'Breed', cat_breed)\n        for col in temp.columns:\n            if col not in ['Breed']:\n                df.loc[idx, f'cat_{col}'] = temp[col].values[0]\n            else:\n                df.loc[idx, f'{col}'] = temp[col].values[0]\n    return df\n\n\ndef resize_to_square(im, img_size):\n    old_size = im.shape[:2]  # old_size is in (height, width) format\n    ratio = float(img_size) / max(old_size)\n    new_size = tuple([int(x * ratio) for x in old_size])\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n    left, right = delta_w // 2, delta_w - (delta_w // 2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n    return new_im\n\n\ndef load_image(path):\n    image = cv2.imread(path).astype(np.float32)\n    new_image = resize_to_square(image)\n    new_image = preprocess_input(new_image)\n    return new_image\n\n\ndef load_image2(path, image_size):\n    image = cv2.imread(path).astype(np.float32)\n    new_image = resize_to_square(image, image_size)\n    new_image = preprocess_input(new_image)\n    return new_image\n\n\ndef getSize(filename):\n    st = os.stat(filename)\n    return st.st_size\n\n\ndef getDimensions(filename):\n    img_size = Image.open(filename).size\n    return img_size\n\n\ndef meta_nlp_feats(df,col):\n    \n    df[col] = df[col].fillna(\"None\")\n    df['length'] = df[col].apply(lambda x : len(x))\n    df['capitals'] = df[col].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n    df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['length']),axis=1)\n    df['num_exclamation_marks'] = df[col].apply(lambda comment: comment.count('!'))\n    df['num_question_marks'] = df[col].apply(lambda comment: comment.count('?'))\n    df['num_punctuation'] = df[col].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n    df['num_symbols'] = df[col].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n    df['num_words'] = df[col].apply(lambda comment: len(comment.split()))\n    df['num_unique_words'] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']\n    df['num_smilies'] = df[col].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\n    df['num_sad'] = df[col].apply(lambda comment: sum(comment.count(w) for w in (':-<', ':()', ';-()', ';(')))\n    \n    return df\n# ============================== PROCESS IN ORDER ===========================\n\n\ndef load_tabular_data():\n    train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\n    test = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\n\n    label_metadata = {}\n    labels_breed = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')\n    labels_color = pd.read_csv('../input/petfinder-adoption-prediction/color_labels.csv')\n    labels_state = pd.read_csv('../input/petfinder-adoption-prediction/state_labels.csv')\n\n    # print(\"Mapping Breed Labels...\")\n    # breed_label_map = {}\n    # for idx, row in (enumerate(labels_breed[['BreedID', 'BreedName']].values)):\n    #     breed_label_map[row[1]] = int(row[0])\n    # temp = parse_sentiment_file('../input/cat-and-dog-breeds-parameters/rating.json')\n    # temp['Breed'] = temp['Breed'].map(breed_label_map)\n    # train = train.merge(temp, how='left', left_on='Breed1', right_on='Breed')\n    # train[temp.columns.tolist()[1:]] = train[temp.columns.tolist()[1:]].fillna(2)\n    # train.drop('Breed', axis=1, inplace=True)\n    # test = test.merge(temp, how='left', left_on='Breed1', right_on='Breed')\n    # test[temp.columns.tolist()[1:]] = test[temp.columns.tolist()[1:]].fillna(2)\n    # test.drop('Breed', axis=1, inplace=True)\n\n    return train, test, labels_state, labels_breed, labels_color\n\n\ndef load_image_data():\n    \n    train_image_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_images/*.jpg'))\n    test_image_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_images/*.jpg'))\n\n    train_df_imgs = pd.DataFrame(train_image_files)\n    train_df_imgs.columns = ['image_filename']\n    train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n    train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n\n    test_df_imgs = pd.DataFrame(test_image_files)\n    test_df_imgs.columns = ['image_filename']\n    test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n    test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n\n    return train_df_imgs, test_df_imgs\n\n\ndef load_metadata():\n    \n    train_metadata_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_metadata/*.json'))\n    test_metadata_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_metadata/*.json'))\n\n    train_df_metadata = pd.DataFrame(train_metadata_files)\n    train_df_metadata.columns = ['metadata_filename']\n    train_metadata_pets = train_df_metadata['metadata_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n    train_df_metadata = train_df_metadata.assign(PetID=train_metadata_pets)\n\n    test_df_metadata = pd.DataFrame(test_metadata_files)\n    test_df_metadata.columns = ['metadata_filename']\n    test_metadata_pets = test_df_metadata['metadata_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n    test_df_metadata = test_df_metadata.assign(PetID=test_metadata_pets)\n\n    return train_df_metadata, test_df_metadata\n\n\ndef load_sentiment_data():\n    train_sentiment_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_sentiment/*.json'))\n    test_sentiment_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_sentiment/*.json'))\n\n    train_df_sentiment = pd.DataFrame(train_sentiment_files)\n    train_df_sentiment.columns = ['sentiment_filename']\n    train_sentiment_pets = train_df_sentiment['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n    train_df_sentiment = train_df_sentiment.assign(PetID=train_sentiment_pets)\n\n    test_df_sentiment = pd.DataFrame(test_sentiment_files)\n    test_df_sentiment.columns = ['sentiment_filename']\n    test_sentiment_pets = test_df_sentiment['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n    test_df_sentiment = test_df_sentiment.assign(PetID=test_sentiment_pets)\n\n    return train_df_sentiment, test_df_sentiment\n\n\ndef build_model(shape=(256, 256, 3), weights_path=\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\"):\n    inp = Input(shape)\n    backbone = DenseNet121(input_tensor=inp,\n                           weights=weights_path,\n                           include_top=False)\n    x = backbone.output\n    x = GlobalAveragePooling2D()(x)\n    x = Lambda(lambda x: K.expand_dims(x, axis=-1))(x)\n    x = AveragePooling1D(4)(x)\n    out = Lambda(lambda x: x[:, :, 0])(x)\n    model = Model(inp, out)\n    return model\n\n\ndef train_model(model, train, test, nn_params={\"batch_size\": 64, \"img_size\": 256}):\n    batch_size = nn_params['batch_size']\n    img_size = nn_params['img_size']\n    pet_ids = train['PetID'].values\n    train_df_ids = train[['PetID']]\n\n    # Train images\n    features = {}\n    train_image = glob.glob(\"../input/petfinder-adoption-prediction/train_images/*.jpg\")\n    n_batches = len(train_image) // batch_size + (len(train_image) % batch_size != 0)\n    for b in (range(n_batches)):\n        start = b * batch_size\n        end = (b + 1) * batch_size\n        batch_pets = train_image[start:end]\n        batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n        for i, pet_id in enumerate(batch_pets):\n            try:\n                batch_images[i] = load_image(pet_id)\n            except:\n                pass\n        batch_preds = model.predict(batch_images)\n        for i, pet_id in enumerate(batch_pets):\n            features[pet_id] = batch_preds[i]\n\n    train_feats = pd.DataFrame.from_dict(features, orient='index')\n    train_feats.columns = ['pic_' + str(i) for i in range(train_feats.shape[1])]\n\n    train_feats = train_feats.reset_index()\n    train_feats['PetID'] = train_feats['index'].apply(lambda x: x.split(\"/\")[-1].split(\"-\")[0])\n    train_feats = train_feats.drop(\"index\", axis=1)\n    train_feats = train_feats.groupby('PetID').agg(\"mean\")\n    train_feats = train_feats.reset_index()\n\n    # Test images\n    features = {}\n\n    test_image = glob.glob(\"../input/petfinder-adoption-prediction/test_images/*.jpg\")\n    n_batches = len(test_image) // batch_size + (len(test_image) % batch_size != 0)\n    for b in (range(n_batches)):\n        start = b * batch_size\n        end = (b + 1) * batch_size\n        batch_pets = test_image[start:end]\n        batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n        for i, pet_id in enumerate(batch_pets):\n            try:\n                batch_images[i] = load_image(pet_id)\n            except:\n                pass\n        batch_preds = model.predict(batch_images)\n        for i, pet_id in enumerate(batch_pets):\n            features[pet_id] = batch_preds[i]\n\n    test_feats = pd.DataFrame.from_dict(features, orient='index')\n    test_feats.columns = ['pic_' + str(i) for i in range(test_feats.shape[1])]\n\n    test_feats = test_feats.reset_index()\n    test_feats['PetID'] = test_feats['index'].apply(lambda x: x.split(\"/\")[-1].split(\"-\")[0])\n    test_feats = test_feats.drop(\"index\", axis=1)\n    test_feats = test_feats.groupby('PetID').agg(\"mean\")\n    test_feats = test_feats.reset_index()\n    pretrained_feats = pd.concat([train_feats, test_feats], axis=0)\n\n    return pretrained_feats\n\n\ndef image_feature(model, train, test, nn_params={\"batch_size\": 64, \"img_size\": 256}):\n    if not preload:\n        batch_size = nn_params['batch_size']\n        img_size = nn_params['img_size']\n        train_df_ids = train[['PetID']]\n\n        # Train images\n        features = {}\n        train_image = glob.glob(\"../input/petfinder-adoption-prediction/train_images/*.jpg\")\n        n_batches = len(train_image) // batch_size + 1\n        for b in (range(n_batches)):\n            start = b * batch_size\n            end = (b + 1) * batch_size\n            batch_pets = train_image[start:end]\n            batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n            for i, pet_id in enumerate(batch_pets):\n                try:\n                    batch_images[i] = load_image2(pet_id, img_size)\n                except:\n                    print(pet_id)\n                    pass\n            batch_preds = model.predict(batch_images)\n            for i, pet_id in enumerate(batch_pets):\n                features[pet_id] = batch_preds[i]\n\n        train_feats = pd.DataFrame.from_dict(features, orient='index')\n        train_feats.columns = ['pic_' + str(i) for i in range(train_feats.shape[1])]\n\n        train_feats = train_feats.reset_index()\n        train_feats['PetID'] = train_feats['index'].apply(lambda x: x.split(\"/\")[-1].split(\"-\")[0])\n        train_feats = train_feats.drop(\"index\", axis=1)\n        train_feats = train_feats.groupby('PetID').agg(\"mean\")\n        train_feats = train_feats.reset_index()\n\n        # Test images\n        features = {}\n\n        test_image = glob.glob(\"../input/petfinder-adoption-prediction/test_images/*.jpg\")\n        n_batches = len(test_image) // batch_size + 1\n        for b in (range(n_batches)):\n            start = b * batch_size\n            end = (b + 1) * batch_size\n            batch_pets = test_image[start:end]\n            batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n            for i, pet_id in enumerate(batch_pets):\n                try:\n                    batch_images[i] = load_image2(pet_id, img_size)\n                except:\n                    print(pet_id)\n                    pass\n            batch_preds = model.predict(batch_images)\n            for i, pet_id in enumerate(batch_pets):\n                features[pet_id] = batch_preds[i]\n\n        test_feats = pd.DataFrame.from_dict(features, orient='index')\n        test_feats.columns = ['pic_' + str(i) for i in range(test_feats.shape[1])]\n\n        test_feats = test_feats.reset_index()\n        test_feats['PetID'] = test_feats['index'].apply(lambda x: x.split(\"/\")[-1].split(\"-\")[0])\n        test_feats = test_feats.drop(\"index\", axis=1)\n        test_feats = test_feats.groupby('PetID').agg(\"mean\")\n        test_feats = test_feats.reset_index()\n        pretrained_feats = pd.concat([train_feats, test_feats], axis=0)\n    else:\n        train_feats = pd.read_csv(\"./processed_data/train_img.csv\")\n        test_feats = pd.read_csv(\"./processed_data/test_img.csv\")\n        pretrained_feats = pd.concat([train_feats, test_feats], axis=0)\n\n    return pretrained_feats\n\n\ndef basic_features(train, test):\n    \n    alldata = pd.concat([train, test], sort=False)\n    print(train.shape, test.shape, alldata.shape)\n    #########################################################################################################\n    # Breed create columns\n    alldata['weeks'] = alldata['Age']*31//7\n    alldata['L_Breed1_Siamese'] =(alldata['Breed1']== 292).astype(int)\n    alldata['L_Breed1_Persian']=(alldata['Breed1']== 285).astype(int)\n    alldata['L_Breed1_Labrador_Retriever']=(alldata['Breed1']== 141).astype(int)\n    alldata['L_Breed1_Terrier']=(alldata['Breed1']==218).astype(int)\n    alldata['L_Breed1_Golden_Retriever ']=(alldata['Breed1']==109).astype(int)\n    alldata['shorthair_hairless_domestic_hair'] = 0\n    alldata.loc[alldata['Breed1'].isin([9 ,104 ,106 ,236 ,237 ,238 ,243 ,244 ,251 ,255 ,264 ,265 ,266 ,268 ,282 ,283 ,298]) == True, 'shorthair_hairless_domestic_hair'] = 1\n    \n    alldata['#Feature_avg_age_breed1_fee'] = alldata[['Age', 'Breed1', 'Fee']].groupby(['Age', 'Breed1'])['Fee'].transform('mean')\n    alldata['#Feature_avg_age_breed2_fee'] = alldata[['Age', 'Breed2', 'Fee']].groupby(['Age', 'Breed2'])['Fee'].transform('mean')\n    alldata['#Feature_age_breed1_maturity_sz'] = alldata[[ 'Age', 'Breed1', 'MaturitySize']].groupby([ 'Age', 'Breed1'])['MaturitySize'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_breed2_maturity_sz'] = alldata[[ 'Age', 'Breed2', 'MaturitySize']].groupby([ 'Age', 'Breed2'])['MaturitySize'].transform('count') / alldata.shape[0]\n    \n    alldata['#Feature_age_breed1_fur'] = alldata[[ 'Age', 'Breed1', 'FurLength']].groupby([ 'Age', 'Breed1'])['FurLength'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_breed2_fur'] = alldata[[ 'Age', 'Breed2', 'FurLength']].groupby([ 'Age', 'Breed2'])['FurLength'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_breed1_fee'] = alldata[[ 'Age', 'Breed1', 'Fee']].groupby([ 'Age', 'Breed1'])['Fee'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_breed2_fee'] = alldata[[ 'Age', 'Breed2', 'Fee']].groupby([ 'Age', 'Breed2'])['Fee'].transform('count') / alldata.shape[0]\n    \n    alldata['#Feature_state_breed1_age_freq']     = alldata[[ 'State', 'Breed1', 'Age']].groupby([ 'State', 'Breed1'])['Age'].transform('mean')\n    alldata['#Feature_state_breed1_age_fee_freq'] = alldata[[ 'State', 'Breed1', 'Age', 'Fee']].groupby([ 'State', 'Breed1', 'Age'])['Fee'].transform('mean')\n    alldata['#Feature_state_breed2_age_freq']     = alldata[[ 'State', 'Breed2', 'Age']].groupby([ 'State', 'Breed2'])['Age'].transform('mean')\n    alldata['#Feature_state_breed2_age_fee_freq'] = alldata[[ 'State', 'Breed2', 'Age', 'Fee']].groupby([ 'State', 'Breed2', 'Age'])['Fee'].transform('mean')\n    \n    alldata['#Feature_avg_type_age_breed1_fee'] = alldata[['Type','Age', 'Breed1', 'Fee']].groupby(['Type','Age', 'Breed1'])['Fee'].transform('mean')\n    alldata['#Feature_avg_type_age_breed2_fee'] = alldata[['Type','Age', 'Breed2', 'Fee']].groupby(['Type','Age', 'Breed2'])['Fee'].transform('mean')\n    alldata['#Feature_age_type_breed1_maturity_sz'] = alldata[['Type', 'Age', 'Breed1', 'MaturitySize']].groupby(['Type', 'Age', 'Breed1'])['MaturitySize'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_type_breed2_maturity_sz'] = alldata[['Type', 'Age', 'Breed2', 'MaturitySize']].groupby(['Type', 'Age', 'Breed2'])['MaturitySize'].transform('count') / alldata.shape[0]\n    \n    alldata['#Feature_age_type_breed1_fur'] = alldata[['Type', 'Age', 'Breed1', 'FurLength']].groupby(['Type', 'Age', 'Breed1'])['FurLength'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_type_breed2_fur'] = alldata[['Type', 'Age', 'Breed2', 'FurLength']].groupby(['Type', 'Age', 'Breed2'])['FurLength'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_type_breed1_fee'] = alldata[['Type', 'Age', 'Breed1', 'Fee']].groupby(['Type', 'Age', 'Breed1'])['Fee'].transform('count') / alldata.shape[0]\n    alldata['#Feature_age_type_breed2_fee'] = alldata[['Type', 'Age', 'Breed2', 'Fee']].groupby(['Type', 'Age', 'Breed2'])['Fee'].transform('count') / alldata.shape[0]\n    \n    alldata['#Feature_state_type_breed1_age_freq']     = alldata[['Type', 'State', 'Breed1', 'Age']].groupby(['Type', 'State', 'Breed1'])['Age'].transform('mean')\n    alldata['#Feature_state_type_breed1_age_fee_freq'] = alldata[['Type', 'State', 'Breed1', 'Age', 'Fee']].groupby(['Type', 'State', 'Breed1', 'Age'])['Fee'].transform('mean')\n    alldata['#Feature_state_type_breed2_age_freq']     = alldata[['Type', 'State', 'Breed2', 'Age']].groupby(['Type', 'State', 'Breed2'])['Age'].transform('mean')\n    alldata['#Feature_state_type_breed2_age_fee_freq'] = alldata[['Type', 'State', 'Breed2', 'Age', 'Fee']].groupby(['Type', 'State', 'Breed2', 'Age'])['Fee'].transform('mean')\n    \n    ###########################################################################################################\n    \n    alldata['RelAge'] = alldata[['Type', 'Age']].apply(relative_age, axis=1)\n    alldata['IsNameGenuine'] = alldata[['Name', 'Quantity']].apply(genuine_name, axis=1)\n    alldata['InstaFeature'] = alldata[['PhotoAmt', 'VideoAmt']].apply(seo_value, axis=1)\n    alldata['ShowsMore'] = alldata['PhotoAmt'].apply(VerifibalePhotoAmy)\n    alldata[\"Vaccinated_Deworked_Mutation\"] = alldata['Vaccinated'].apply(str) + \"_\" + alldata['Dewormed'].apply(str)\n    alldata[\"Vaccinated_Deworked_Mutation\"] = alldata['Vaccinated'].apply(str) + \"_\" + alldata['Dewormed'].apply(str)\n    alldata = pd.get_dummies(alldata, columns=['Vaccinated_Deworked_Mutation'], prefix=\"Vaccinated_Dewormed\")\n    alldata['GlobalInstaRank'] = alldata['InstaFeature'].rank(method='max')\n    print(\">> Ranking Features By State\")\n    alldata = rankbyG(alldata, \"State\")\n    print(\">> Ranking Features By Animal\")\n    alldata = rankbyG(alldata, \"Type\")\n    print(\">> Ranking Features By Breed1\")\n    alldata = rankbyG(alldata, \"Breed1\")\n    print(\">> Ranking Features By Gender\")\n    alldata = rankbyG(alldata, \"Gender\")\n\n    top_dogs = [179, 205, 195, 178, 206, 109, 189, 103]\n    top_cats = [276, 268, 285, 252, 243, 251, 288, 247, 280, 290]\n\n    alldata['#Feature_SecondaryColors'] = alldata['Color2'] + alldata['Color3']\n    alldata['#Feature_MonoColor'] = np.where(alldata['#Feature_SecondaryColors'], 1, 0)\n    alldata['top_breeds'] = 0\n    alldata.loc[alldata['Breed1'].isin(top_dogs + top_cats) == True, 'top_breeds'] = 1\n    alldata['top_breed_free'] = 0\n    alldata.loc[alldata[(alldata['Fee'] == 0) & (alldata['top_breeds'] == 1)].index, 'top_breed_free'] = 1\n    alldata['free_pet'] = 0\n    alldata.loc[alldata[alldata['Fee'] == 0].index, 'free_pet'] = 1\n    alldata['free_pet_age_1'] = 0\n    alldata.loc[alldata[(alldata['Fee'] == 0) & (alldata['Age'] == 1)].index, 'free_pet_age_1'] = 1\n    alldata['year'] = alldata['Age'] / 12.\n    alldata['#Feature_less_a_year'] = np.where(alldata['Age'] < 12, 1, 0)\n    alldata['#Feature_top_2_states'] = 0\n    alldata.loc[alldata['State'].isin([41326, 41401]) == True, '#Feature_top_2_states'] = 1\n    alldata['#Feature_age_exact'] = 0\n    alldata.loc[alldata['Age'].isin([12, 24, 36, 48, 60, 72, 84, 96, 108]) == True, '#Feature_age_exact'] = 1\n    alldata['#Feature_isLonely'] = np.where(alldata['Quantity'] > 1, 1, 0)\n    alldata['total_img_video'] = alldata['PhotoAmt'] + alldata['VideoAmt']\n    \n    # alldata['#Feature_avg_age_breed1_fee'] = alldata[['Age', 'Breed1', 'Fee']].groupby(['Age', 'Breed1'])[\n    #     'Fee'].transform('mean')\n    # alldata['#Feature_avg_age_breed2_fee'] = alldata[['Age', 'Breed2', 'Fee']].groupby(['Age', 'Breed2'])[\n    #     'Fee'].transform('mean')\n    # alldata['#Feature_age_breed1_maturity_sz'] = alldata[['Age', 'Breed1', 'MaturitySize']].groupby(['Age', 'Breed1'])[\n    #                                                  'MaturitySize'].transform('count') / alldata.shape[0]\n    # alldata['#Feature_age_breed2_maturity_sz'] = alldata[['Age', 'Breed2', 'MaturitySize']].groupby(['Age', 'Breed2'])[\n    #                                                  'MaturitySize'].transform('count') / alldata.shape[0]\n    # alldata['#Feature_age_breed1_fur'] = alldata[['Age', 'Breed1', 'FurLength']].groupby(['Age', 'Breed1'])[\n    #                                          'FurLength'].transform('count') / alldata.shape[0]\n    # alldata['#Feature_age_breed2_fur'] = alldata[['Age', 'Breed2', 'FurLength']].groupby(['Age', 'Breed2'])[\n    #                                          'FurLength'].transform('count') / alldata.shape[0]\n    # alldata['#Feature_age_breed1_fee'] = alldata[['Age', 'Breed1', 'Fee']].groupby(['Age', 'Breed1'])['Fee'].transform(\n    #     'count') / alldata.shape[0]\n    # alldata['#Feature_age_breed2_fee'] = alldata[['Age', 'Breed2', 'Fee']].groupby(['Age', 'Breed2'])['Fee'].transform(\n    #     'count') / alldata.shape[0]\n    # alldata['#Feature_state_breed1_age_freq'] = alldata[['State', 'Breed1', 'Age']].groupby(['State', 'Breed1'])[\n    #     'Age'].transform('mean')\n    # alldata['#Feature_state_breed1_age_fee_freq'] = \\\n    # alldata[['State', 'Breed1', 'Age', 'Fee']].groupby(['State', 'Breed1', 'Age'])['Fee'].transform('mean')\n    # alldata['#Feature_state_breed2_age_freq'] = alldata[['State', 'Breed2', 'Age']].groupby(['State', 'Breed2'])[\n    #     'Age'].transform('mean')\n    # alldata['#Feature_state_breed2_age_fee_freq'] = \\\n    # alldata[['State', 'Breed2', 'Age', 'Fee']].groupby(['State', 'Breed2', 'Age'])['Fee'].transform('mean')\n\n    # Clean the name\n    # alldata['Name'] = alldata['Name'].apply(lambda x: clean_name(x))\n    # alldata['Name'] = alldata['Name'].fillna(\"No Name\")\n\n    rescuer_count = alldata.groupby(['RescuerID'])['PetID'].count().reset_index()\n    rescuer_count.columns = ['RescuerID', 'RescuerID_COUNT']\n    alldata = alldata.merge(rescuer_count, how='left', on='RescuerID')\n\n    Description_count = alldata.groupby(['Description'])['PetID'].count().reset_index()\n    Description_count.columns = ['Description', 'Description_COUNT']\n    alldata = alldata.merge(Description_count, how='left', on='Description')\n\n    Name_count = alldata.groupby(['Name'])['PetID'].count().reset_index()\n    Name_count.columns = ['Name', 'Name_COUNT']\n    alldata = alldata.merge(Name_count, how='left', on='Name')\n\n    agg = {}\n    agg['Quantity'] = ['mean', 'var', 'max', 'min', 'skew', 'median']\n    agg['Fee'] = ['mean', 'var', 'max', 'min', 'skew', 'median']\n    agg['Age'] = ['mean', 'sum', 'var', 'max', 'min', 'skew', 'median']\n    agg['Breed1'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Breed2'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Type'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Gender'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Color1'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Color2'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Color3'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['MaturitySize'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['FurLength'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Vaccinated'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Sterilized'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg['Health'] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg[\"PhotoAmt\"] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n    agg[\"RelAge\"] = ['nunique', 'var', 'max', 'min', 'skew', 'median']\n\n    # RescuerID\n    grouby = 'RescuerID'\n    agg_df = agg_features(alldata, grouby, agg, grouby)\n    alldata = alldata.merge(agg_df, on=grouby, how='left')\n    \n    agg_kurt_df = alldata.groupby(grouby)[list(agg.keys())].apply(pd.DataFrame.kurt)\n    agg_kurt_df.columns = [f\"{key}_kurt\" for key in list(agg.keys())]\n    alldata = alldata.merge(agg_kurt_df, on=grouby, how='left')\n    \n    agg_perc_df = alldata.groupby(grouby)[list(agg.keys())].quantile(.25)\n    agg_perc_df.columns = [f\"{key}_perc_25\" for key in list(agg.keys())]\n    alldata = alldata.merge(agg_perc_df, on=grouby, how='left')\n    \n    agg_perc_df = alldata.groupby(grouby)[list(agg.keys())].quantile(.75)\n    agg_perc_df.columns = [f\"{key}_perc_75\" for key in list(agg.keys())]\n    alldata = alldata.merge(agg_perc_df, on=grouby, how='left')\n    \n    \n    # State\n    \n    ################################################CREATING MULTIPLE COLUMNS WITH_X NEED TO BE FIXED\n    grouby = 'State'\n    agg_df = agg_features(alldata, grouby, agg, grouby)\n    alldata = alldata.merge(agg_df, on=grouby, how='left')\n    \n    agg_kurt_df = alldata.groupby(grouby)[list(agg.keys())].apply(pd.DataFrame.kurt)\n    agg_kurt_df.columns = [f\"{key}_kurt\" for key in list(agg.keys())]\n    alldata = alldata.merge(agg_kurt_df, on=grouby, how='left')\n    \n    agg_perc_df = alldata.groupby(grouby)[list(agg.keys())].quantile(.25)\n    agg_perc_df.columns = [f\"{key}_perc_25\" for key in list(agg.keys())]\n    alldata = alldata.merge(agg_perc_df, on=grouby, how='left')\n    \n    agg_perc_df = alldata.groupby(grouby)[list(agg.keys())].quantile(.75)\n    agg_perc_df.columns = [f\"{key}_perc_75\" for key in list(agg.keys())]\n    alldata = alldata.merge(agg_perc_df, on=grouby, how='left')\n\n    train = alldata[:len(train)]\n    test  = alldata[len(train):]\n\n    return train, test\n\n\ndef image_dim_features(train, test):\n    # Load IDs and Image data\n    # ===========================================\n    split_char = \"/\"\n    train_df_ids = train[['PetID']]\n    test_df_ids = test[['PetID']]\n\n    train_image_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_images/*.jpg'))\n    test_image_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_images/*.jpg'))\n\n    train_df_imgs = pd.DataFrame(train_image_files)\n    train_df_imgs.columns = ['image_filename']\n    train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n    train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n\n    test_df_imgs = pd.DataFrame(test_image_files)\n    test_df_imgs.columns = ['image_filename']\n    test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n    test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n\n    # ===========================================\n\n    train_df_imgs['image_size'] = train_df_imgs['image_filename'].apply(getSize)\n    train_df_imgs['temp_size'] = train_df_imgs['image_filename'].apply(getDimensions)\n    train_df_imgs['width'] = train_df_imgs['temp_size'].apply(lambda x: x[0])\n    train_df_imgs['height'] = train_df_imgs['temp_size'].apply(lambda x: x[1])\n    train_df_imgs = train_df_imgs.drop(['temp_size'], axis=1)\n\n    test_df_imgs['image_size'] = test_df_imgs['image_filename'].apply(getSize)\n    test_df_imgs['temp_size'] = test_df_imgs['image_filename'].apply(getDimensions)\n    test_df_imgs['width'] = test_df_imgs['temp_size'].apply(lambda x: x[0])\n    test_df_imgs['height'] = test_df_imgs['temp_size'].apply(lambda x: x[1])\n    test_df_imgs = test_df_imgs.drop(['temp_size'], axis=1)\n\n    aggs = {\n        'image_size': ['sum', 'mean', 'var'],\n        'width': ['sum', 'mean', 'var'],\n        'height': ['sum', 'mean', 'var'],\n    }\n\n    agg_train_imgs = train_df_imgs.groupby('PetID').agg(aggs)\n    new_columns = [\n        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n    ]\n    agg_train_imgs.columns = new_columns\n    agg_train_imgs = agg_train_imgs.reset_index()\n\n    agg_test_imgs = test_df_imgs.groupby('PetID').agg(aggs)\n    new_columns = [\n        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n    ]\n    agg_test_imgs.columns = new_columns\n    agg_test_imgs = agg_test_imgs.reset_index()\n\n    agg_imgs = pd.concat([agg_train_imgs, agg_test_imgs], axis=0).reset_index(drop=True)\n    return agg_imgs\n\n\ndef metadata_features(train, test):\n\n    if not preload:\n        train_pet_ids = train.PetID.unique()\n        test_pet_ids = test.PetID.unique()\n\n        # Train Feature Extractions\n        # ===============================\n\n        dfs_train = Parallel(n_jobs=12, verbose=1)(\n            delayed(extract_additional_features)(i, mode='train') for i in train_pet_ids)\n        train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n        train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n        train_dfs_sentiment = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n        train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n\n        # Test Feature Extractions\n        # ===============================\n        dfs_test = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)\n        test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n        test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n        test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n        test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n\n    else:\n        train_dfs_sentiment = pd.read_csv(\"./processed_data/train_dfs_sentiment.csv\")\n        train_dfs_metadata = pd.read_csv(\"./processed_data/train_dfs_metadata.csv\")\n        test_dfs_sentiment = pd.read_csv(\"./processed_data/test_dfs_sentiment.csv\")\n        test_dfs_metadata = pd.read_csv(\"./processed_data/test_dfs_metadata.csv\")\n\n        train_dfs_sentiment['sentiment_entities'].fillna('', inplace=True)\n        train_dfs_metadata['metadata_annots_top_desc'].fillna('', inplace=True)\n        test_dfs_sentiment['sentiment_entities'].fillna('', inplace=True)\n        test_dfs_metadata['metadata_annots_top_desc'].fillna('', inplace=True)\n\n\n    # Meta data Aggregates\n    # ===============================\n    aggregates = ['mean', 'sum', 'var']\n\n    # Train Aggregates\n    # ---------------------------\n    train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n    train_metadata_desc = train_metadata_desc.reset_index()\n    train_metadata_desc['metadata_annots_top_desc'] = train_metadata_desc['metadata_annots_top_desc'].apply(\n        lambda x: ' '.join(x.tolist()))\n\n    prefix = 'metadata'\n    train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n    for i in train_metadata_gr.columns:\n        if 'PetID' not in i:\n            train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n    train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n    train_metadata_gr.columns = pd.Index(['{}_{}_{}'.format(\n        prefix, c[0], c[1].upper()) for c in train_metadata_gr.columns.tolist()])\n    train_metadata_gr = train_metadata_gr.reset_index()\n\n    train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n    train_sentiment_desc = train_sentiment_desc.reset_index()\n    train_sentiment_desc['sentiment_entities'] = train_sentiment_desc['sentiment_entities'].apply(\n        lambda x: ' '.join(x.tolist()))\n\n    prefix = 'sentiment'\n    train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n    for i in train_sentiment_gr.columns:\n        if 'PetID' not in i:\n            train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n    train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(aggregates)\n    train_sentiment_gr.columns = pd.Index(['{}_{}_{}'.format(\n        prefix, c[0], c[1].upper()) for c in train_sentiment_gr.columns.tolist()])\n    train_sentiment_gr = train_sentiment_gr.reset_index()\n\n    # Test data Aggregates\n    # ---------------------------\n    test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n    test_metadata_desc = test_metadata_desc.reset_index()\n    test_metadata_desc[\n        'metadata_annots_top_desc'] = test_metadata_desc[\n        'metadata_annots_top_desc'].apply(lambda x: ' '.join(x.tolist()))\n\n    prefix = 'metadata'\n    test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n    for i in test_metadata_gr.columns:\n        if 'PetID' not in i:\n            test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n    test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n    test_metadata_gr.columns = pd.Index(['{}_{}_{}'.format(\n        prefix, c[0], c[1].upper()) for c in test_metadata_gr.columns.tolist()])\n    test_metadata_gr = test_metadata_gr.reset_index()\n\n    test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n    test_sentiment_desc = test_sentiment_desc.reset_index()\n    test_sentiment_desc[\n        'sentiment_entities'] = test_sentiment_desc[\n        'sentiment_entities'].apply(lambda x: ' '.join(x.tolist()))\n\n    prefix = 'sentiment'\n    test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n    for i in test_sentiment_gr.columns:\n        if 'PetID' not in i:\n            test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n    test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(aggregates)\n    test_sentiment_gr.columns = pd.Index(['{}_{}_{}'.format(\n        prefix, c[0], c[1].upper()) for c in test_sentiment_gr.columns.tolist()])\n    test_sentiment_gr = test_sentiment_gr.reset_index()\n\n\n    # Mergining Features with Train/Test\n    # =======================================\n    train_proc = train.copy()\n    train_proc = train_proc.merge(train_sentiment_gr, how='left', on='PetID')\n    train_proc = train_proc.merge(train_metadata_gr, how='left', on='PetID')\n    train_proc = train_proc.merge(train_metadata_desc, how='left', on='PetID')\n    train_proc = train_proc.merge(train_sentiment_desc, how='left', on='PetID')\n\n    test_proc = test.copy()\n    test_proc = test_proc.merge(test_sentiment_gr, how='left', on='PetID')\n    test_proc = test_proc.merge(test_metadata_gr, how='left', on='PetID')\n    test_proc = test_proc.merge(test_metadata_desc, how='left', on='PetID')\n    test_proc = test_proc.merge(test_sentiment_desc, how='left', on='PetID')\n\n    return train_proc, test_proc\n\n\ndef breed_maps(train_proc, test_proc, labels_breed):\n    train_breed_main = train_proc[['Breed1']].merge(labels_breed, how='left', left_on='Breed1', right_on='BreedID',\n                                                    suffixes=('', '_main_breed'))\n    train_breed_main = train_breed_main.iloc[:, 2:]\n    train_breed_main = train_breed_main.add_prefix('main_breed_')\n    train_breed_second = train_proc[['Breed2']].merge(labels_breed, how='left', left_on='Breed2', right_on='BreedID',\n                                                      suffixes=('', '_second_breed'))\n    train_breed_second = train_breed_second.iloc[:, 2:]\n    train_breed_second = train_breed_second.add_prefix('second_breed_')\n    train_proc = pd.concat([train_proc, train_breed_main, train_breed_second], axis=1)\n    test_breed_main = test_proc[['Breed1']].merge(labels_breed, how='left', left_on='Breed1', right_on='BreedID',\n                                                  suffixes=('', '_main_breed'))\n    test_breed_main = test_breed_main.iloc[:, 2:]\n    test_breed_main = test_breed_main.add_prefix('main_breed_')\n    test_breed_second = test_proc[['Breed2']].merge(labels_breed, how='left', left_on='Breed2', right_on='BreedID',\n                                                    suffixes=('', '_second_breed'))\n    test_breed_second = test_breed_second.iloc[:, 2:]\n    test_breed_second = test_breed_second.add_prefix('second_breed_')\n    test_proc = pd.concat([test_proc, test_breed_main, test_breed_second], axis=1)\n    X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)\n    categorical_columns = ['main_breed_BreedName', 'second_breed_BreedName']\n\n    for i in categorical_columns:\n        X.loc[:, i] = pd.factorize(X.loc[:, i])[0]\n    return X\n\n\ndef nlp_features(X_temp):\n    text_columns = ['Description', 'metadata_annots_top_desc', 'sentiment_entities']\n    X_text = X_temp[text_columns]\n\n    for i in X_text.columns:\n        X_text.loc[:, i] = X_text.loc[:, i].fillna('<MISSING>')\n\n    n_components = 50\n    text_features = []\n\n    # Generate text features:\n    for i in X_text.columns:\n        # Initialize decomposition methods:\n        print('Generating features from: {}'.format(i))\n        svd_ = TruncatedSVD(n_components=n_components, random_state=1337)\n        nmf_ = NMF(n_components=n_components, random_state=1337)\n        tfidf_col = TfidfVectorizer().fit_transform(X_text.loc[:, i].values)\n        svd_col = svd_.fit_transform(tfidf_col)\n        svd_col = pd.DataFrame(svd_col)\n        svd_col = svd_col.add_prefix('SVD_{}_'.format(i))\n        nmf_col = nmf_.fit_transform(tfidf_col)\n        nmf_col = pd.DataFrame(nmf_col)\n        nmf_col = nmf_col.add_prefix('NMF_{}_'.format(i))\n        text_features.append(svd_col)\n        text_features.append(nmf_col)\n\n    # Combine all extracted features:\n    text_features = pd.concat(text_features, axis=1)\n    # Concatenate with main DF:\n    X_temp = pd.concat([X_temp, text_features], axis=1)\n    # Remove raw text columns:\n    for i in X_text.columns:\n        X_temp = X_temp.drop(i, axis=1)\n    # Remove unnecessary columns:\n    to_drop_columns = ['PetID', 'Name']\n    X_temp = X_temp.drop(to_drop_columns, axis=1)\n\n    return X_temp\n\n\ndef run_lgbm(X_temp, test):\n    params = {'application': 'regression',\n              'boosting': 'gbdt',\n              'metric': 'rmse',\n              'num_leaves': 70,\n              'max_depth': 9,\n              'learning_rate': 0.01,\n              'bagging_fraction': 0.6,  # .85 previously\n              'feature_fraction': 0.6,  # .8 previously\n              'min_split_gain': 0.02,\n              'min_child_samples': 150,\n              'min_child_weight': 0.02,\n              'lambda_l2': 0.0475,\n              'verbosity': -1,\n              'data_random_seed': 17,\n              }\n    # Additional parameters:\n    early_stop = 500\n    verbose_eval = 500\n    num_rounds = 10000\n    n_splits = 10\n\n    # Split into train and test again:\n    X_train = X_temp.loc[np.isfinite(X_temp.AdoptionSpeed), :]\n    X_test = X_temp.loc[~np.isfinite(X_temp.AdoptionSpeed), :]\n\n    # Remove missing target column from test:\n    X_test = X_test.drop(['AdoptionSpeed'], axis=1)\n\n    print('X_train shape: {}'.format(X_train.shape))\n    print('X_test shape: {}'.format(X_test.shape))\n\n    # Check if columns between the two DFs are the same:\n    train_cols = X_train.columns.tolist()\n    train_cols.remove('AdoptionSpeed')\n    train_cols.remove('RescuerID')\n\n    test_cols = X_test.columns.tolist()\n\n    kfold = StratifiedKFold(n_splits=n_splits, random_state=1337)\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    rescuer_gb_mean = X_train.groupby('RescuerID')['AdoptionSpeed'].agg(\"mean\").reset_index()\n    rescuer_gb_mean.columns = ['RescuerID', 'AdoptionSpeed_mean']\n\n    rescuer_ids = rescuer_gb_mean['RescuerID'].values\n    rescuer_as_mean = rescuer_gb_mean['AdoptionSpeed_mean'].values\n\n    i = 0\n\n    for train_index, valid_index in kfold.split(rescuer_ids, rescuer_as_mean.astype(np.int)):\n        rescuser_train_ids = rescuer_ids[train_index]\n        rescuser_valid_ids = rescuer_ids[valid_index]\n\n        X_tr = X_train[X_train[\"RescuerID\"].isin(rescuser_train_ids)]\n        X_val = X_train[X_train[\"RescuerID\"].isin(rescuser_valid_ids)]\n\n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed', 'RescuerID'], axis=1)\n\n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed', 'RescuerID'], axis=1)\n\n        print('\\ny_tr distribution: {}'.format(Counter(y_tr)))\n\n        d_train = lgb.Dataset(X_tr, label=y_tr)\n        d_valid = lgb.Dataset(X_val, label=y_val)\n        watchlist = [d_train, d_valid]\n\n        print('training LGB:')\n        model = lgb.train(params,\n                          train_set=d_train,\n                          num_boost_round=num_rounds,\n                          valid_sets=watchlist,\n                          verbose_eval=verbose_eval,\n                          early_stopping_rounds=early_stop\n                          )\n\n        val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n        test_pred = model.predict(X_test.drop([\"RescuerID\"], axis=1), num_iteration=model.best_iteration)\n\n        oof_train[X_val.index] = val_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n\n    imp_df = pd.DataFrame()\n    imp_df[\"feature\"] = list(train_cols)\n    imp_df[\"importance_gain\"] = model.feature_importance(importance_type='gain')\n    imp_df[\"importance_split\"] = model.feature_importance(importance_type='split')\n    imp_df.to_csv('imps.csv', index=False)\n\n    # Compute QWK based on OOF train predictions:\n    optR = OptimizedRounder()\n    optR.fit(oof_train, X_train['AdoptionSpeed'].values)\n    coefficients = optR.coefficients()\n    pred_test_y_k = optR.predict(oof_train, coefficients)\n    print(\"\\nValid Counts = \", Counter(X_train['AdoptionSpeed'].values))\n    print(\"Predicted Counts = \", Counter(pred_test_y_k))\n    print(\"Coefficients = \", coefficients)\n    qwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, pred_test_y_k)\n    print(\"QWK = \", qwk)\n\n    coefficients_ = coefficients.copy()\n    print(f'coefficients returned From optim for LGBM are {coefficients_}')\n\n    coefficients_[0] = 1.645\n    #coefficients_[1] = 2.115\n    #coefficients_[3] = 2.84\n\n    print(f'coefficients actually used are {coefficients_}')\n\n    train_predictions = optR.predict(oof_train, coefficients_).astype(int)\n    print('train pred distribution: {}'.format(Counter(train_predictions)))\n\n    test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_)\n    print('test pred distribution: {}'.format(Counter(test_predictions)))\n\n    # Distribution inspection of original target and predicted train and test:\n    print(\"True Distribution:\")\n    print(pd.value_counts(X_train['AdoptionSpeed'], normalize=True).sort_index())\n    print(\"\\nTrain Predicted Distribution:\")\n    print(pd.value_counts(train_predictions, normalize=True).sort_index())\n    print(\"\\nTest Predicted Distribution:\")\n    print(pd.value_counts(test_predictions, normalize=True).sort_index())\n    submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions.astype(np.uint16)})\n    return submission, oof_train, oof_test, model\n\n\ndef run_xgb(X_temp, test):\n \n    params = {'eval_metric': 'rmse',\n              'seed': 1337,\n              'eta': 0.0123,\n              'subsample': 0.7,\n              'colsample_bytree': 0.75,\n              'tree_method': 'gpu_hist',\n              'device': 'gpu',\n              'silent': 1,\n              'gamma' : 8,\n              'max_depth' : 7\n              }\n    n_splits = 10\n    verbose_eval = 1000\n    num_rounds = 10000\n    early_stop = 500\n    \n    # Split into train and test again:\n    X_train = X_temp.loc[np.isfinite(X_temp.AdoptionSpeed), :]\n    X_test = X_temp.loc[~np.isfinite(X_temp.AdoptionSpeed), :]\n\n    # Remove missing target column from test:\n    X_test = X_test.drop(['AdoptionSpeed', \"RescuerID\"], axis=1)\n\n    print('X_train shape: {}'.format(X_train.shape))\n    print('X_test shape: {}'.format(X_test.shape))\n\n    # Check if columns between the two DFs are the same:\n    train_cols = X_train.columns.tolist()\n    train_cols.remove('AdoptionSpeed')\n    train_cols.remove('RescuerID')\n\n    test_cols = X_test.columns.tolist()\n\n    kfold = StratifiedKFold(n_splits=n_splits, random_state=1337)\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    rescuer_gb_mean = X_train.groupby('RescuerID')['AdoptionSpeed'].agg(\"mean\").reset_index()\n    rescuer_gb_mean.columns = ['RescuerID', 'AdoptionSpeed_mean']\n\n    rescuer_ids = rescuer_gb_mean['RescuerID'].values\n    rescuer_as_mean = rescuer_gb_mean['AdoptionSpeed_mean'].values\n\n    i = 0\n\n    for train_index, valid_index in kfold.split(X_train, X_train['AdoptionSpeed'].astype(np.int)):\n        print(f'Fold {i+1}')\n\n        X_tr = X_train.iloc[train_index]\n        X_val = X_train.iloc[valid_index]\n\n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed', 'RescuerID'], axis=1)\n\n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed', 'RescuerID'], axis=1)\n\n        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n\n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n                          early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n\n        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n\n        oof_train[X_val.index] = valid_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n\n    optR = OptimizedRounder()\n    optR.fit(oof_train, X_train['AdoptionSpeed'].values)\n    coefficients = optR.coefficients()\n    valid_pred = optR.predict(oof_train, coefficients)\n    qwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, valid_pred)\n    print(\"QWK = \", qwk)\n    coefficients_ = coefficients.copy()\n    print(f'coefficients returned From optim for XGB are {coefficients_}')\n    coefficients_[0] = 1.645\n    # coefficients_[1] = 2.115\n    # coefficients_[3] = 2.84\n    print(f'coefficients used for XGB are {coefficients_}')\n    train_predictions = optR.predict(oof_train, coefficients_).astype(np.int8)\n    print(f'train pred distribution: {Counter(train_predictions)}')\n    test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)\n    print(f'test pred distribution: {Counter(test_predictions)}')\n\n    submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions})\n    return submission, oof_train, oof_test, model\n\n\nset_seed(2411)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain, test, labels_state, labels_breed, labels_color = load_tabular_data()\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain, test = basic_features(train, test)\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain =  meta_nlp_feats(train, 'Description')\ntest  =  meta_nlp_feats(test,  'Description')\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = bounding_features(train, meta_path=\"../input/petfinder-adoption-prediction/train_metadata/\")\ntest  = bounding_features(test, meta_path=\"../input/petfinder-adoption-prediction/test_metadata/\")\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain, test = metadata_features(train, test)\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef add_noise(series, noise_level):\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\ndef target_encode(trn_series=None,tst_series=None,target=None,min_samples_leaf=1,smoothing=1,noise_level=0):\n    \"\"\"\n    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n    trn_series : training categorical feature as a pd.Series\n    tst_series : test categorical feature as a pd.Series\n    target : target data as a pd.Series\n    min_samples_leaf (int) : minimum samples to take category average into account\n    smoothing (int) : smoothing effect to balance categorical average vs prior  \n    \"\"\" \n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean \n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index \n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n###########################################################################\n#######################################################################\n\ntrn, sub = target_encode(train[\"Breed1\"], \n                         test[\"Breed1\"], \n                         target=train.AdoptionSpeed, \n                         min_samples_leaf=100,\n                         smoothing=10,\n                         noise_level=0.01)\ntrain['tencode_breed1'] = trn\ntest['tencode_breed1'] = sub\n\ntrn, sub = target_encode(train[\"Breed2\"], \n                         test[\"Breed2\"], \n                         target=train.AdoptionSpeed, \n                         min_samples_leaf=100,\n                         smoothing=10,\n                         noise_level=0.01)\ntrain['tencode_breed2'] = trn\ntest['tencode_breed2'] = sub\n\ntrn, sub = target_encode(train[\"Age\"], \n                         test[\"Age\"], \n                         target=train.AdoptionSpeed, \n                         min_samples_leaf=100,\n                         smoothing=10,\n                         noise_level=0.01)\ntrain['tencode_Age'] = trn\ntest['tencode_Age'] = sub\n\ndel trn, sub\ngc.collect()\n\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsentimental_analysis = sorted(glob.glob('../input/petfinder-adoption-prediction/train_sentiment/*.json'))\n#Define Empty lists\nscore=[]\nmagnitude=[]\npetid=[]\n\nfor filename in sentimental_analysis:\n    with open(filename, 'r') as f:\n        sentiment_file = json.load(f)\n    file_sentiment = sentiment_file['documentSentiment']\n    file_score =  np.asarray(sentiment_file['documentSentiment']['score'])\n    file_magnitude =np.asarray(sentiment_file['documentSentiment']['magnitude'])\n    score.append(file_score)\n    magnitude.append(file_magnitude)\n    petid.append(filename.replace('.json','').replace('../input/petfinder-adoption-prediction/train_sentiment/', ''))\n\n# Output with sentiment data for each pet\n# Output with sentiment data for each pet\nsentimental_analysis = pd.concat([ pd.DataFrame(petid, columns =['PetID']) ,pd.DataFrame(score, columns =['sentiment_document_score']),\n                                                pd.DataFrame(magnitude, columns =['sentiment_document_magnitude'])],axis =1)\n\ntrain = pd.merge(train, sentimental_analysis, how='left', on='PetID')\n\nsentimental_analysis = sorted(glob.glob('../input/petfinder-adoption-prediction/test_sentiment/*.json'))\n#Define Empty lists\nscore=[]\nmagnitude=[]\npetid=[]\n\nfor filename in sentimental_analysis:\n    with open(filename, 'r') as f:\n        sentiment_file = json.load(f)\n    file_sentiment = sentiment_file['documentSentiment']\n    file_score =  np.asarray(sentiment_file['documentSentiment']['score'])\n    file_magnitude =np.asarray(sentiment_file['documentSentiment']['magnitude'])\n    score.append(file_score)\n    magnitude.append(file_magnitude)\n    petid.append(filename.replace('.json','').replace('../input/petfinder-adoption-prediction/test_sentiment/', ''))\n\n# Output with sentiment data for each pet\n# Output with sentiment data for each pet\nsentimental_analysis = pd.concat([ pd.DataFrame(petid, columns =['PetID']) ,pd.DataFrame(score, columns =['sentiment_document_score']),\n                                                pd.DataFrame(magnitude, columns =['sentiment_document_magnitude'])],axis =1)\n\ntest = pd.merge(test, sentimental_analysis, how='left', on='PetID')\ndel sentimental_analysis, score, magnitude, petid\ngc.collect()\n\ntrain['neg_sentiment'] = 0\ntrain.loc[train[(train['sentiment_document_score'] < 0)].index, 'neg_sentiment'] = 1\n\ntest['neg_sentiment'] = 0\ntest.loc[test[(test['sentiment_document_score'] < 0)].index, 'neg_sentiment'] = 1\n\nprint(\"TRAIN:\", train.shape)\nprint(\"TEST:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_temp = breed_maps(train, test, labels_breed)\n\nkeywords = ['urgent', 'lost', 'fast', 'left', 'immediate', 'critical', 'rescued', 'free', 'trained']\nval = []\nfor idx in range(X_temp.shape[0]):\n    i = ''\n    i = X_temp.loc[idx,'Description']\n    if not isinstance(i,float):\n        if 'trained' in i: \n            val.append(1)\n        elif 'urgent' in i:\n            val.append(1)\n        elif 'lost' in i:\n            val.append(1)\n        elif 'fast' in i:\n            val.append(1)\n        elif 'left' in i:\n            val.append(1)\n        elif 'immediate' in i:\n            val.append(1)\n        elif 'rescued' in i:\n            val.append(1)\n        else:\n            val.append(0)\n    else:\n#         print(i)\n        val.append(0)\nprint(len(val), X_temp.shape)\nX_temp['keywords'] = val\ndel val\ngc.collect()\n\nprint(\"TRAIN/TEST:\", X_temp.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndenseNet121 = build_model()\n\npretrained_feats = image_feature(denseNet121, train, test)\n\nX_temp = X_temp.merge(pretrained_feats, how='left', on='PetID')\nprint(\"TRAIN/TEST:\", X_temp.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"denseNet121.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nX_feat = nlp_features(X_temp)\nprint(\"TRAIN/TEST:\", X_feat.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef fuze(train, test):\n    working_train = (train.dtypes != 'object')\n    working_test = (test.dtypes != 'object') \n    variables = list(set(train.columns[working_train]) & set(test.columns[working_test]))\n    return list(set(variables + ['AdoptionSpeed', 'RescuerID'])), variables\n\nworking_train, working_test = fuze(X_temp, test)\nnew_test = test.loc[:,working_test].copy()\nnew_test['AdoptionSpeed'] = np.nan\nnew_test['RescuerID'] = np.nan\n\n(a, b) = (train.loc[:,working_train].append(new_test),\n\n(a, b) = (X_temp.loc[:,working_train],\n               test.loc[:,working_test+['PetID']])\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_feat = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#### TRAINING\n\nlgb_submission, lgb_oof_train, lgb_oof_test, lgb_imp = run_lgbm(X_feat, test_feat)\nlgb_submission.to_csv(\"submission_lgb.csv\", index=None)\n\nfrom numba import cuda\ncuda.close()\n\nxgb_submission, xgb_oof_train, xgb_oof_test, xgb_imp = run_xgb(X_feat, test_feat)\nxgb_submission.to_csv(\"submission_xgb.csv\", index=None)\n\n# Blend\nsubmission = lgb_submission[['PetID']]\nsubmission['AdoptionSpeed'] = (lgb_submission.AdoptionSpeed + xgb_submission.AdoptionSpeed)/2\nsubmission['AdoptionSpeed'] = submission.AdoptionSpeed.astype(int)\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_score = lgb_imp.feature_importance(importance_type='split')\nlgb_score2 = lgb_imp.feature_importance(importance_type='gain')\nxgb_score = xgb_imp.get_fscore()\nfeatures = [f for f in X_feat.columns if f not in ['AdoptionSpeed', \"RescuerID\"]]\nxs = [0 if f not in xgb_score else xgb_score[f] for f in features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance = pd.DataFrame({'feature':features, 'lgb_imp':lgb_score, 'lgb_imp_gain':lgb_score2, 'xgb_imp':xs})\nimportance.to_csv('importance.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\n\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='submission_lgb.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='submission_xgb.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='importance.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}